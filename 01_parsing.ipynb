{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First lets import some libraries we will use...\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "xyz_path = 'na.xyz'     # File path\n",
    "nframe = 2000           # Number of frames (or snapshots)\n",
    "nat = 195               # Number of atoms\n",
    "a = 12.55               # Cell size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First approach\n",
    "\n",
    "Write a function that reads an xyz trajectory file in. We are going to need to be able to separate numbers from atomic symbols; an XYZ trajectory file looks like:\n",
    "\n",
    "```\n",
    "nat [unit]\n",
    "[first frame]\n",
    "symbol1 x11 y11 z11\n",
    "symbol2 x21 y21 z21\n",
    "nat [unit]\n",
    "[second frame]\n",
    "symbol1 x12 y12 z12\n",
    "symbol2 x22 y22 z22\n",
    "```\n",
    "\n",
    "Stuff in [ ] are optional (if units are absent, angstroms are assumed; a blank is included if no comments are present).\n",
    "\n",
    "Here is an example file parser. All it does is read line by line and return a list of these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def skeleton_naive_xyz_parser(path):\n",
    "    '''\n",
    "    Simple xyz parser.\n",
    "    '''\n",
    "    # Read in file\n",
    "    lines = None\n",
    "    with open(path) as f:    \n",
    "        lines = f.readlines()\n",
    "    # Process lines\n",
    "    # Return processed lines\n",
    "    return lines\n",
    "\n",
    "lines = skeleton_naive_xyz_parser(xyz_path)\n",
    "lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CODING TIME: Try to expand the skeleton above to convert the line strings into \n",
    "into a list of xyz data rows (i.e. convert the strings to floats).**\n",
    "\n",
    "If you can't figure out any approach, run the cell below which will print one possible (of many) ways of \n",
    "approaching this problem (*note that you may have to run the cell twice*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load -s naive_xyz_parser, snippets/parsing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = naive_xyz_parser(xyz_path)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataFrames\n",
    "\n",
    "People spend a lot of time reading code, especially their own code.\n",
    "Lets do two things in using DataFrames: make our code more readable\n",
    "and *not* reinvent the wheel (i.e. parsers). We have pride in the \n",
    "code we write! First an example of using DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed = 1\n",
    "df = pd.DataFrame(np.random.randint(0, 10, size=(6, 4)), columns=['A', 'B', 'C', 'D'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df += 1\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.loc[:, 'A'] = [0, 0, 1, 1, 2, 2]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.groupby('A')[['B', 'C', 'D']].apply(lambda f: f.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second approach: pandas.read_csv\n",
    "\n",
    "Like 99% (my estimate) of all widely established Python packages, pandas is very well \n",
    "[documented](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "Let's use this function of pandas to read in our well structured xyz data. The **names** argument (see function below) allows us to specific the column names\n",
    "and the **delim_whitespace** arguments means that we parse tsv (tab or space separated files).\n",
    "\n",
    "**CODING TIME: Figure out what options we need to correctly parse in the XYZ trajectory data using pandas.read_csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skeleton_pandas_xyz_parser(path):\n",
    "    '''\n",
    "    Parses xyz files using pandas read_csv function.\n",
    "    '''\n",
    "    # Read from disk\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['symbol', 'x', 'y', 'z'])\n",
    "    # Remove nats and comments\n",
    "    # \n",
    "    #\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = skeleton_pandas_xyz_parser(xyz_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible solution (**run this only if you have already finished the above!**):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load -s pandas_xyz_parser, snippets/parsing.py\n",
    "def pandas_xyz_parser(path):\n",
    "    '''\n",
    "    Parse xyz files using pandas read_csv.\n",
    "\n",
    "    Args:\n",
    "        path (str): XYZ file path\n",
    "\n",
    "    Returns:\n",
    "        df (:class:`pandas.DataFrame`): Table of XYZ data\n",
    "    '''\n",
    "    df = pd.read_csv(path, delim_whitespace=True, names=['symbol', 'x', 'y', 'z'])    # Read data from disk\n",
    "    indexes_to_discard = df.loc[df['symbol'].str.isdigit(), 'symbol'].index           # Get indexes of nat lines\n",
    "    indexes_to_discard = indexes_to_discard.append(indexes_to_discard + 1)            # and comment lines\n",
    "    df = df.loc[~df.index.isin(indexes_to_discard)].reset_index(drop=True)            # Discard them\n",
    "    df[['x', 'y', 'z']] = df[['x', 'y', 'z']].astype(np.float)                        # Convert types\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas_xyz_parser(xyz_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing your functions is key\n",
    "\n",
    "A couple of quick tests should suffice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(df) == nframe * nat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets attach a useful index (for later)\n",
    "\n",
    "This is easy since we know the number of atoms and number of frames..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pandas_xyz_parser(xyz_path)\n",
    "df.index = pd.MultiIndex.from_product((range(nframe), range(nat)), names=['frame', 'atom'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load -s parse, snippets/parsing.py\n",
    "def parse(path, nframe, nat):\n",
    "    '''\n",
    "    Complete parsing of xyz files.\n",
    "    '''\n",
    "    df = pandas_xyz_parser(path)\n",
    "    df.index = pd.MultiIndex.from_product((range(nframe), range(nat)), names=['frame', 'atom'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving your work!\n",
    "\n",
    "We did all of this work parsing our data, but this Python kernel won't be alive eternally so lets save\n",
    "our data so that we can load it later (i.e. in the next notebook!).\n",
    "\n",
    "We are going to create an [HDF5](https://www.hdfgroup.org/HDF5/) store for saving our DataFrame(s) to. HDF is a high performance,\n",
    "portable, binary data storage format designed with scientific data exchange in mind. Use it! Also note that\n",
    "pandas has [extensive](http://pandas.pydata.org/pandas-docs/stable/io.html) IO functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xyz = parse(xyz_path, nframe, nat)\n",
    "store = pd.HDFStore('xyz.hdf5', mode='w', complevel=9, complib='zlib')\n",
    "store.put('xyz', xyz)\n",
    "store.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though there are a bunch of improvements/features we could make to our parse function...\n",
    "\n",
    "# ...lets move on to step [two](02_distances.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
